#!/usr/bin/env python
import sys
import warnings
import os
import tempfile
import streamlit as st
import time
from dotenv import load_dotenv
from pydantic import BaseModel
from datetime import datetime
from loaders import *
from langchain_community.chat_message_histories import ChatMessageHistory
#from crew_inicial import Crew_inicial
from teste  import AnaliseArtefatosFlow, run_flow, set_status_callback
import asyncio
#from crew_analise2 import Project_2

warnings.filterwarnings("ignore", category=SyntaxWarning, module="pysbd")

load_dotenv()

# Vari√°veis obrigat√≥rias para Azure OpenAI
api_key = os.getenv("AZURE_API_KEY2")
api_base = os.getenv("AZURE_API_BASE2")
api_version = os.getenv("AZURE_API_VERSION")
#model_name = os.getenv("OPENAI_MODEL_NAME")


# Constantes
TIPOS_ARQUIVOS_VALIDOS = ['Site', 'Pdf', 'Csv', 'Txt']
MODELOS_PROXY = [
    'azure/bnb-gpt-4.1', 'azure/bnb-gpt-4.1-mini', 'azure/bnb-gpt-4.1-nano',
    'azure/bnb-gpt-4o', 'azure/bnb-gpt-4o-mini', 'azure/bnb-llama-3.3-70B'
]
MEMORIA = ChatMessageHistory()

# Fun√ß√£o para carregar arquivos
def carrega_arquivos(tipo_arquivo, arquivo):
    if tipo_arquivo == 'Site':
        return carrega_site(arquivo)
    if tipo_arquivo in ['Pdf', 'Csv', 'Txt']:
        ext = tipo_arquivo.lower()
        with tempfile.NamedTemporaryFile(suffix=f'.{ext}', delete=False) as temp:
            temp.write(arquivo.read())
            nome_temp = temp.name
        if tipo_arquivo == 'Pdf':
            return carrega_pdf(nome_temp)
        elif tipo_arquivo == 'Csv':
            return carrega_csv(nome_temp)
        elif tipo_arquivo == 'Txt':
            return carrega_txt(nome_temp)

def montar_mensagem_sistema(tipo_arquivo, documento):
    #personalidade = carrega_txt('./personalidade2.md')
    #ref_medicoes = carrega_txt('./ref_medicoes.md')
    mensagem = f"\n"
    if tipo_arquivo and documento:
        mensagem += f"{documento}."
    return mensagem


def carrega_varios_arquivos(tipo_arquivo, arquivos):
    conteudos = []
    if tipo_arquivo == 'Site':
        for url in arquivos:
            try:
                conteudo = carrega_site(url)
                conteudos.append(f"[{url}]:\n{conteudo}")
            except Exception as e:
                conteudos.append(f"[{url}]: Erro ao carregar ({e})")
    else:
        for arquivo in arquivos:
            try:
                conteudo = carrega_arquivos(tipo_arquivo, arquivo)
                nome = getattr(arquivo, 'name', 'arquivo')
                conteudos.append(f"[{nome}]:\n{conteudo}")
            except Exception as e:
                nome = getattr(arquivo, 'name', 'arquivo')
                conteudos.append(f"[{nome}]: Erro ao carregar ({e})")
    return "\n\n".join(conteudos)

def chamar_crew(api_key, model_name, mensagens, max_tokens=10000, temperature=1.0, top_p=1.0):
    """
    Fun√ß√£o modificada para incluir informativos visuais durante o processamento
    """
    
    #st.session_state['processando'] = True


    # Cria containers para status din√¢mico
    status_container = st.empty()
    progress_bar = st.progress(0)
    details_container = st.empty()
    
    # Define callback para receber atualiza√ß√µes do teste.py
    def status_callback(message: str, progress: int):
        status_container.info(message)
        progress_bar.progress(progress)
        
        # Adiciona detalhes espec√≠ficos baseados no progresso
        if progress == 15:
            time.sleep(1)
            details_container.markdown("""
            **üîç Classifica√ß√£o de Entrada:**
            - Identificando tipo de conte√∫do
            - Determinando agente especializado
            """)
        elif progress == 40:
            time.sleep(1)
            details_container.markdown("""
            **üìä Categoriza√ß√£o em Andamento:**
            - Linguagem de Programa√ß√£o
            - Arquitetura de Sistemas  
            - Infraestrutura
            - Banco de Dados
            - DevSecOps / Governan√ßa
            """)
        elif progress == 65:
            time.sleep(1)
            details_container.markdown("""
            **üî¨ An√°lises Especializadas:**
            - ‚úÖ Linguagens avaliadas
            - ‚úÖ Sistemas analisados
            - üîÑ Infraestrutura em an√°lise
            - ‚è≥ Banco de dados pendente
            - ‚è≥ DevSecOps pendente
            """)
        elif progress == 85:
            time.sleep(1)
            details_container.markdown("""
            **üîí Finalizando An√°lises:**
            - ‚úÖ Linguagens conclu√≠das
            - ‚úÖ Sistemas conclu√≠dos
            - ‚úÖ Infraestrutura conclu√≠da
            - ‚úÖ Banco de dados conclu√≠do
            - üîÑ DevSecOps em an√°lise
            """)
        elif progress >= 95:
            time.sleep(1)
            details_container.markdown("""
            **üìà Consolida√ß√£o Final:**
            - ‚úÖ Todas as an√°lises conclu√≠das
            - üîÑ Gerando relat√≥rio t√©cnico
            - üìä Calculando m√©tricas de modernidade
            """)
    
    try:
        # Configura o callback no teste.py
        set_status_callback(status_callback)
        
        # Fase inicial: Prepara√ß√£o
        status_container.info("üîÑ **Preparando an√°lise:** Configurando agentes especializados...")
        progress_bar.progress(5)
        
        # Processa as mensagens
        topic = ""
        if isinstance(mensagens, list):
            for nome, conteudo in mensagens:
                topic += f"\n[{nome}]: {conteudo}"
        else:
            topic = mensagens
        
        topic = {'input': topic}
        
        # Configura o fluxo
        AnaliseArtefatosFlow.configure(
            api_key=api_key,
            api_base=api_base,
            api_version=api_version,
            model_name=model_name,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p
        )
        
        # Executa o fluxo (que agora enviar√° atualiza√ß√µes via callback)
        resposta = asyncio.run(run_flow(topic))
        
        # Sucesso final
        status_container.success("‚úÖ **An√°lise conclu√≠da!** Relat√≥rio t√©cnico gerado com sucesso.")
        details_container.empty()
        
        # Remove elementos ap√≥s delay
        time.sleep(1)
        status_container.empty()
        progress_bar.empty()
        
        return resposta
        
    except Exception as e:
        status_container.error(f"‚ùå **Erro durante processamento:** {str(e)}")
        progress_bar.empty()
        details_container.empty()
        st.error("Falha na an√°lise. Verifique os logs para mais detalhes.")
        return f"Erro durante processamento: {str(e)}"
    finally:
        # Limpa o callback
        set_status_callback(None)
#        st.session_state['processando'] = False

def pagina_chat():
    st.header('ü§ñ Bem-vindo ao IAM (IA de Moderniza√ß√£o)', divider=True)

    modelo = st.session_state.get('modelo')
    api_key = st.session_state.get('api_key')
    system_message = st.session_state.get('system_message')
    documento = st.session_state.get('documento', None)  # Novo: guarda o texto do documento

    # Inicializa o estado de processamento se n√£o existir
    if 'processando' not in st.session_state:
        st.session_state['processando'] = False

    if not all([modelo, system_message]):
        st.error('Carregue o Or√°culo primeiro.')
        st.stop()

    memoria = st.session_state.get('memoria', MEMORIA)
    for mensagem in memoria.messages:
        chat = st.chat_message(mensagem.type)
        chat.markdown(mensagem.content)


    # Exibe mensagem informativa quando est√° processando
    if st.session_state['processando']:
        st.info("üîÑ **Processamento em andamento...** Por favor, aguarde a conclus√£o da an√°lise.")
        st.chat_input(placeholder="Aguarde o processamento atual terminar...", disabled=True)
    
        # Container para exibir o processamento em tempo real
        processing_container = st.container()
        with processing_container:
            st.markdown("### üîÑ **Status do Processamento**")   
    
    
    else:
        input_usuario = st.chat_input(placeholder='Fale com o Or√°culo')
        
        if input_usuario:
            # IMEDIATAMENTE define o estado como processando e for√ßa rerun
            st.session_state['processando'] = True
            
            # Adiciona a mensagem do usu√°rio ao chat
            chat = st.chat_message('human')
            chat.markdown(input_usuario)
            
            # Adiciona √† mem√≥ria
            memoria = st.session_state.get('memoria', MEMORIA)
            memoria.add_user_message(input_usuario)
            st.session_state['memoria'] = memoria
            
            # For√ßa a atualiza√ß√£o da interface para mostrar o estado de processamento
            st.rerun()

    # Processamento real - s√≥ executa quando h√° input pendente
    if st.session_state['processando'] and 'input_pendente' not in st.session_state:
        # Recupera a √∫ltima mensagem do usu√°rio
        memoria = st.session_state.get('memoria', MEMORIA)
        if memoria.messages and memoria.messages[-1].type == 'human':
            input_usuario = memoria.messages[-1].content
            
            # Processa documentos
            documentos = []
            contador = 1
            if documento:
                for bloco in documento.split('---DOCUMENTO---'):
                    if bloco.strip():
                        nome = f"documento{contador}"
                        conteudo = bloco.strip()
                        documentos.append((nome, conteudo))
                        contador = contador + 1
            else:
                documentos = []
            
            documentos.append(("InputUsuario", input_usuario))

            # Executa o processamento
            try:
                if documentos:
                    resposta = chamar_crew(api_key, modelo, documentos)
                else:
                    resposta = chamar_crew(api_key, modelo, input_usuario)
                    
                # Mostra a resposta
                chat = st.chat_message('ai')
                chat.markdown(resposta)
                
                # Adiciona √† mem√≥ria
                memoria.add_ai_message(resposta)
                st.session_state['memoria'] = memoria
                
            except Exception as e:
                st.error(f"Erro durante o processamento: {str(e)}")
                
            finally:
                # SEMPRE libera o estado de processamento
                st.session_state['processando'] = False
                # For√ßa atualiza√ß√£o para liberar o input
                st.rerun()

# Sidebar
def sidebar():
    tabs = st.tabs(['Upload de Arquivos', 'Sele√ß√£o de Modelos'])
    with tabs[0]:
        # Campo para m√∫ltiplas URLs
        urls = st.text_area('Digite uma ou mais URLs (uma por linha)')
        lista_urls = [url.strip() for url in urls.splitlines() if url.strip()]

        # Campo para m√∫ltiplos arquivos de qualquer tipo permitido
        tipo_arquivo = st.selectbox('Selecione o tipo de arquivo', TIPOS_ARQUIVOS_VALIDOS[1:])  # Exclui 'Site'
        arquivos = st.file_uploader(
            f'Fa√ßa o upload de um ou mais arquivos {tipo_arquivo.lower()}',
            type=[tipo_arquivo.lower()],
            accept_multiple_files=True
        )

    with tabs[1]:
        modelo = st.selectbox('Selecione o modelo do Proxy', MODELOS_PROXY)
        # API Key agora √© sempre lida do ambiente, n√£o h√° input do usu√°rio
        #api_key = os.getenv("AZURE_API_KEY")
        st.session_state['api_key'] = api_key

    if st.button('Inicializar Or√°culo', use_container_width=True):
        documento = ""
        # Junta conte√∫dos de sites
        if lista_urls:
            conteudo_sites = carrega_varios_arquivos('Site', lista_urls)
            documento += '\n---DOCUMENTO---\n' + conteudo_sites.strip()
        # Junta conte√∫dos de arquivos
        if arquivos:
            conteudo_arquivos = carrega_varios_arquivos(tipo_arquivo, arquivos)
            documento += '\n---DOCUMENTO---\n' + conteudo_arquivos.strip()
        
        if not documento:
            documento = None

        system_message = montar_mensagem_sistema('M√∫ltiplos', documento)
        st.session_state['system_message'] = system_message
        st.session_state['modelo'] = modelo
        st.session_state['documento'] = documento  # Pode ser None

    if st.button('Apagar Hist√≥rico de Conversa', use_container_width=True):
        st.session_state['memoria'] = MEMORIA
        st.session_state['documento'] = None  # Limpa o documento tamb√©m

# ...existing code..

# Main
def main():
    with st.sidebar:
        sidebar()
    pagina_chat()

if __name__ == '__main__':
    main()
